# Alignment Handbook Sandbox
a folder to run various experiments with the alignment handbook

- SFT of LLM using HF tooling [youtube](https://www.youtube.com/watch?v=NXevvEF3QVI&t=1070s) , [reference notbook](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Mistral/Supervised_fine_tuning_(SFT)_of_an_LLM_using_Hugging_Face_tooling.ipynb)
    - Making LLMs even more accessible with bnb, 4-bit quantization and QLoRA [HF Blog](https://huggingface.co/blog/4bit-transformers-bitsandbytes)
    - Pytorch Blog on finetuning LLM [Blog](https://pytorch.org/blog/finetune-llms/), [colab](https://colab.research.google.com/drive/1vIjBtePIZwUaHWfjfNHzBjwuXOyU_ugD?usp=sharing)
- Preference Tuning LLMs with Direct Preference Optimization Methods ([HF Blog](https://huggingface.co/blog/pref-tuning))
    - consider extending it to compare with PPO
    

